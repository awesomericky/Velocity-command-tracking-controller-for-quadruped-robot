seed: 1
record_video: yes
logging: True

environment:
  render: True
  # just testing commenting
  evaluate: False
  determine_env: 0  # 0: not determine / 1: circle / 2: box / 3: corridor
  num_envs: 500
  max_n_update: 30000
  eval_every_n: 100
  new_environment_every_n: 100
  seed:
    train: 0
    evaluate: 600
  num_threads: 12 # 4 is (optimal for data collection)
  test_num_threads: 3  # Number of threads for evaluating model based RL
  simulation_dt: 0.0025
  control_dt: 0.01
  max_time: 6.0
  command_period: 0.5
  obstacle_grid_size:
    min: 3.0
    max: 5.0
  n_rewards: 4
  reward:
    goal_distance:
      coeff: 1.0
    goal_terminate:
      coeff: 1.0
    obstacle_terminate:
      coeff: -1.0
    traversal_distance:
      coeff: -1.0
  command:
    forward_vel:
      min: -1.0
      max: 1.0
    lateral_vel:
      min: -0.4
      max: 0.4
    yaw_rate:
      min: -1.2
      max: 1.2
  randomization: False  # 1) Base COM position, 2) Mass of links, 3) Joint position
  random_initialize: False  # used for training
  random_external_force: False  # 50N force for 1s for lateral direction
  point_goal_initialize: False  # used for evaluating

training:
  learning_rate: 3e-4
  batch_size: 512
  num_epochs: 8
  shuffle_batch: True
  clip_gradient: True
  max_gradient_norm: 2.0

architecture:
  use_latent_state: False
  state_encoder: # state = lidar + (encoded COM history)
    input: 450  # COM_encoder output is included in the input  (360 + 32)
    output: 100
    shape: [ 256, 256, 128, 128 ]
    activation: leakyrelu
    dropout: 0.2
    batchnorm: True
  policy_net: [128, 128]
  value_net: [128, 128]